{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import sqlite3 as sq\n",
    "import functools\n",
    "import numpy as np\n",
    "import ipyparallel as ipp\n",
    "import os\n",
    "import re\n",
    "import pprint\n",
    "from textblob import TextBlob\n",
    "import functools\n",
    "import itertools\n",
    "import pickle\n",
    "import collections\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRABRADLEX = True\n",
    "GRABREPORTS = True\n",
    "GRABMARKUPS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADDIR = os.path.join(os.path.expanduser('~'),'Box Sync', 'GradSchoolStuff', 'MastersProject', 'radlex')\n",
    "os.path.exists(RADDIR)\n",
    "print(\"RADDIR: \", RADDIR)\n",
    "# this appears to not be used at all\n",
    "#NLPDIR = os.path.join(os.path.expanduser('~'),'Dropbox','NLP')\n",
    "#os.path.exists(NLPDIR)\n",
    "#print(\"NLPDIR: \", NLPDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before this block can be run, execute \"ipcluster start -n 4\" via commandline\n",
    "# see more info at http://ipyparallel.readthedocs.org/en/stable/process.html\n",
    "rc = ipp.Client()\n",
    "\n",
    "dview = rc[:]\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dview.sync_imports():\n",
    "    from textblob import TextBlob\n",
    "    import numpy\n",
    "    #import tagObjects\n",
    "    import pyConTextNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g=rdflib.Graph()\n",
    "g.load(os.path.join(RADDIR,\"Radlex_3.12.owl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example RadLex queries](http://www.khresmoi.eu/assets/Deliverables/WP5/KhresmoiD5.4.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qres = g.query(\"\"\"SELECT DISTINCT ?type WHERE {?s a ?type.}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In creating the regular expressions from the RadLex terms, I've learned from sad (and slow) experience the need to have the word boundaries around the phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regex(r1,r2):\n",
    "    if r2:\n",
    "        return r\"\\b%s\\b|\\b%s\\b\"%(r1,r2)\n",
    "    else:\n",
    "        return r\"\\b%s\\b\"%r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grabradlex: \", GRABRADLEX)\n",
    "if GRABRADLEX:\n",
    "    g = rdflib.Graph()\n",
    "    #result = g.parse(\"http://data.bioontology.org/ontologies/RADLEX/download?apikey=8b5b7825-538d-40e0-9e9e-5ab9274a9aeb&download_format=rdf\",\n",
    "    #                 format=\"xml\")\n",
    "    \n",
    "    result = g.parse(os.path.join(RADDIR, 'Radlex3.13.1.owl'), format=\"xml\")\n",
    "    print(\"result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyConTextNLP.functional.itemData as ID\n",
    "import pyConTextNLP.functional.conTextItem as CI\n",
    "import pyConTextNLP.functional.ConTextMarkup as CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRABRADLEX:\n",
    "    g = rdflib.Graph()\n",
    "    #result = g.parse(\"http://data.bioontology.org/ontologies/RADLEX/download?apikey=8b5b7825-538d-40e0-9e9e-5ab9274a9aeb&download_format=rdf\",\n",
    "    #                 format=\"xml\")\n",
    "    \n",
    "    result = g.parse(os.path.join(RADDIR, 'Radlex3.13.1.owl'), format=\"xml\")\n",
    "\n",
    "    query_results = {}\n",
    "    types = [\"anatomy_metaclass\",\"pathophysiology_metaclass\",\"imaging_observation_metaclass\"]\n",
    "    q1 = \"\"\" \n",
    "\n",
    "    PREFIX Ontology1447432460: <http://www.owl-ontologies.com/Ontology1447432460.owl#>\n",
    "\n",
    "    SELECT DISTINCT ?s ?preferred_name ?synonym ?type\n",
    "\n",
    "    WHERE {\n",
    "\n",
    "        ?s Ontology1447432460:Preferred_name ?preferred_name. \n",
    "        ?s rdf:type ?type\n",
    "        OPTIONAL {?s Ontology1447432460:Synonym ?synonym.}\n",
    "\n",
    "        FILTER  regex(str(?type), \"%s\")}\"\"\"\n",
    "    #print(q1)\n",
    "\n",
    "    for t in types:\n",
    "        q = q1%t\n",
    "        print(q)\n",
    "        query_results[t] = g.query(q)\n",
    "\n",
    "    for t,r in query_results.items():\n",
    "        print(t,len(r))\n",
    "        print(\"*\"*42)\n",
    "\n",
    "    rslts = g.query(q)\n",
    "\n",
    "    itemData = {}\n",
    "    for t in types:\n",
    "        itemData[t] = [CI.create_ConTextItem([r[1],\n",
    "                                              r[3].split(\"#\")[1],\n",
    "                                              create_regex(r[1],r[2]),\n",
    "                                              \"\"]) \\\n",
    "                    for r in query_results[t]]\n",
    "    with open(os.path.join(RADDIR,\"DBs\",\"radlex.pickle\"),\"wb\") as f0:\n",
    "        pickle.dump(itemData,f0)\n",
    "else:\n",
    "    with open(os.path.join(RADDIR,\"DBs\",\"radlex.pickle\"),\"rb\") as f0:\n",
    "        itemData = pickle.load(f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for r in query_results[\"pathophysiology_metaclass\"]:\n",
    "    print(r[1],r[2])\n",
    "    count += 1\n",
    "    if count >=50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do some printing for verifying things look as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in itemData['pathophysiology_metaclass'][0:50]:\n",
    "    print(i)\n",
    "    #print(\"LITERAL: %s; RE: %s\"%(i.literal, i.re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tmp = [r for r in query_results[\"pathophysiology_metaclass\"] \\\n",
    "                                if \"short bowel\" in r[1]]\n",
    "tmp[0][2].toPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import functional form of pyConTextNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_conTextMarkup(s, targets ):\n",
    "    markup = CM.create_ConTextMarkup()\n",
    "    markup = CM.setRawText(markup, s)\n",
    "    markup = CM.cleanText(markup)\n",
    "    markup = CM.mark_items_in_text(markup, targets, mode=\"target\")\n",
    "    markup = CM.pruneMarks(markup)\n",
    "    markup = CM.dropMarks(markup, category='Exclusion')\n",
    "    # apply modifiers to any targets within the modifiers scope\n",
    "    return markup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the IPython parallel function to speed up the processing\n",
    "\n",
    "I've had difficulty getting functools partial to build up a robust set of functions with the arguments frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_conTextMarkup_parallel(sentences, targets, mode):\n",
    "    mark_items_in_text = functools.partial(CM.mark_items_in_text,\n",
    "                                           items=targets, \n",
    "                                           mode=mode)\n",
    "    dropMarks = functools.partial(CM.dropMarks, category='Exclusion')\n",
    "    sm = [CM.create_ConTextMarkup() for i in range(len(sentences))]\n",
    "    sm = dview.map_async(CM.setRawText, sm, sentences).get()\n",
    "    sm = dview.map_async(CM.cleanText,sm).get()\n",
    "    sm = dview.map_async(mark_items_in_text,sm).get()\n",
    "    sm = dview.map_async(CM.pruneMarks,sm).get()\n",
    "    sm = dview.map_async(dropMarks,sm).get()\n",
    "    return sm\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # apply modifiers to any targets within the modifiers scope\n",
    "    return markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = []\n",
    "for key,items in itemData.items():\n",
    "    all_items.extend(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data\n",
    "\n",
    "Pull all the reports from the database and convert to individual sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRABREPORTS:\n",
    "    conn = sq.connect(os.path.join(RADDIR,\"DBs\",\n",
    "                                   \"criticalFindingsAll.sqlite\"))\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    r_date  = re.compile(r\"\"\"([0-9]{1,2}(/[0-9]{1,2})?/[0-9]{2,4})\"\"\")\n",
    "    r_time = re.compile(r\"\"\"([0-9]{1,2}:\\d\\d(pm|am)?)\"\"\")\n",
    "    cursor.execute(\"\"\"SELECT rowid,impression from reports\"\"\")\n",
    "    data = [(d[0],d[1].lower()) for d in cursor.fetchall()]\n",
    "    data =[(d[0],r_date.sub(\"\",r_time.sub(\"\",d[1]))) for d in data]\n",
    "\n",
    "    reports = [d[1] for d in data]\n",
    "\n",
    "    def report2sentences(report):\n",
    "        return TextBlob(report).raw_sentences\n",
    "\n",
    "    sentences = list(itertools.chain.from_iterable(dview.map_async(report2sentences,reports).get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markup sentences with pyConTextNLP items generated from RadLex\n",
    "\n",
    "Keep non-zero markups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRABMARKUPS:\n",
    "    allMarkups = create_sentence_conTextMarkup_parallel(sentences, \n",
    "                                           all_items,\n",
    "                                           mode=\"target\")\n",
    "\n",
    "    detected_all = [p for p in allMarkups if p.nodes()]\n",
    "    print(len(detected_all))\n",
    "\n",
    "\n",
    "    import gzip\n",
    "    with gzip.open(os.path.join(RADDIR,\"NLP\",\"DBs\",\"radlex_found_sentences.pickle\"),\"wb\") as f0:\n",
    "        pickle.dump(detected_all,f0)\n",
    "else:\n",
    "    with gzip.open(os.path.join(RADDIR,\"NLP\",\"DBs\",\"radlex_found_sentences.pickle\"),\"rb\") as f0:\n",
    "        detected_all = pickle.load(f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pathoMarkups = create_sentence_conTextMarkup_parallel(sentences, \n",
    "                                       itemData['pathophysiology_metaclass'],\n",
    "                                       mode=\"target\")\n",
    "\n",
    "detected_patho = [p for p in pathoMarkups if p.nodes()]\n",
    "print(len(detected_patho))\n",
    "\n",
    "anatMarkups = create_sentence_conTextMarkup_parallel(sentences, \n",
    "                                       itemData['anatomy_metaclass'],\n",
    "                                       mode=\"target\")\n",
    "detected_anat = [p for p in anatMarkups if p.nodes()]\n",
    "print(len(detected_anat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(detected_all[i].nodes())\n",
    "    print(detected_all[i].graph[\"__text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeReport(report, targets ):\n",
    "        \"\"\"\n",
    "        given an individual radiology report, creates a pyConTextGraph\n",
    "        object that contains the context markup\n",
    "        report: a text string containing the radiology reports\n",
    "        \"\"\"\n",
    "        sentences = report2sentences(report)\n",
    "        markups = list(map(create_sentence_conTextMarkup,sentences, report, targets,[]))\n",
    "        return markups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = sq.connect(os.path.join(RADDIR,\"radlex_terms_expanded.sqlite\"))\n",
    "cu2 = c2.cursor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}