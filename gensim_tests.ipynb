{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "sqlitedb = os.path.join(os.path.expanduser('~'),'Box Sync', 'GradSchoolStuff', 'MastersProject', 'ctpa.sqlite')\n",
    "if not (os.path.exists(sqlitedb)):\n",
    "    print(\"Specified database does not exist\")\n",
    "    sys.exit()\n",
    "\n",
    "connection = sqlite3.connect(sqlitedb)\n",
    "with connection:\n",
    "    cur = connection.cursor()\n",
    "    cur.execute('select * from reports limit 1')\n",
    "    col_names = [cn[0] for cn in cur.description]\n",
    "    rows = cur.fetchall()\n",
    "    #print(len(rows[0]))\n",
    "    #print(\"%s %s %s %s %s %s\" % (col_names[0], col_names[1], col_names[2], col_names[3], col_names[4], col_names[5]))\n",
    "\n",
    "    document = [row[4] for row in rows][0]\n",
    "    document = document.strip() # remove trailing and leading spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(document)\\nfor o in output:\\n    print('START: ', o)\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data\n",
    "\n",
    "# Load the punkt tokenizer pre-trained on english text\n",
    "# to improve sentence splitting, would need to create custom tokenizer that understands sections\n",
    "# however, I think this may be good enoug for now.\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "output = sent_tokenizer.tokenize(document)\n",
    "output = [o.strip() for o in output]\n",
    "\n",
    "# alternatively could use NLTK sentence splitter, but don't like how \"we'll\" becomes two words \"we\" and \"'ll\"\n",
    "output = [o.lower().split() for o in output]\n",
    "\n",
    "'''\n",
    "print(document)\n",
    "for o in output:\n",
    "    print('START: ', o)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "# Set values for various parameters, starting point provided by \n",
    "# https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 5    # Minimum word count, default is 5\n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "# default sample = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "model = word2vec.Word2Vec(output, \\\n",
    "                          workers=num_workers, \\\n",
    "                          size=num_features, \\\n",
    "                          min_count = min_word_count, \\\n",
    "                          window = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
